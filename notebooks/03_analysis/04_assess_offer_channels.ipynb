{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = pd.read_pickle(r'data\\04_fct\\fct_demographic_offers_and_transactions.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8011710025955212,\n",
       "   Feature  Importance\n",
       " 0  mobile    0.055459\n",
       " 1  social    0.932559\n",
       " 2     web    0.011982)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Use a decision tree classifier to determine channel importance ###\n",
    "# Extract features and target variable\n",
    "features = data_new[['mobile', 'social', 'web']]\n",
    "target = data_new['offer_viewed']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the decision tree classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Extract feature importances\n",
    "feature_importances = clf.feature_importances_\n",
    "\n",
    "# Create a DataFrame to display feature importances\n",
    "importance_df = pd.DataFrame({'Feature': ['mobile', 'social', 'web'], 'Importance': feature_importances})\n",
    "\n",
    "# Display the results\n",
    "accuracy, importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree classifier achieved an accuracy of approximately 80.12%. The social channel was the most important factor in determining whether an offer was viewed, followed by the mobile channel and then the web channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8011710025955212,\n",
       "   Feature  Importance\n",
       " 0  mobile    0.204546\n",
       " 1  social    0.757655\n",
       " 2     web    0.037800)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train the random forest classifier\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_rf_pred = rf_clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "rf_accuracy = accuracy_score(y_test, y_rf_pred)\n",
    "\n",
    "# Extract feature importances\n",
    "rf_feature_importances = rf_clf.feature_importances_\n",
    "\n",
    "# Create a DataFrame to display feature importances\n",
    "rf_importance_df = pd.DataFrame({'Feature': ['mobile', 'social', 'web'], 'Importance': rf_feature_importances})\n",
    "\n",
    "# Display the results\n",
    "rf_accuracy, rf_importance_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a Random Forest classifier, we achieved an accuracy of approximately 80.12%. The social channel remains the most significant factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative                1121                2691\n",
      "Actual Positive                 603               12152\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score       support\n",
      "0              0.650232  0.294071  0.404986   3812.000000\n",
      "1              0.818702  0.952724  0.880644  12755.000000\n",
      "accuracy       0.801171  0.801171  0.801171      0.801171\n",
      "macro avg      0.734467  0.623398  0.642815  16567.000000\n",
      "weighted avg   0.779938  0.801171  0.771197  16567.000000\n",
      "\n",
      "ROC-AUC Score:\n",
      "   ROC-AUC Score\n",
      "0       0.833973\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_rf_pred)\n",
    "\n",
    "# Classification Report\n",
    "class_report = classification_report(y_test, y_rf_pred)\n",
    "\n",
    "# ROC-AUC Score\n",
    "roc_auc = roc_auc_score(y_test, rf_clf.predict_proba(X_test)[:, 1])\n",
    "\n",
    "# Convert the confusion matrix to a DataFrame\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=['Actual Negative', 'Actual Positive'], columns=['Predicted Negative', 'Predicted Positive'])\n",
    "\n",
    "# Convert the classification report to a DataFrame\n",
    "# The output format of classification_report changed in newer versions of scikit-learn, so ensure compatibility\n",
    "report_dict = classification_report(y_test, y_rf_pred, output_dict=True)\n",
    "class_report_df = pd.DataFrame(report_dict).transpose()\n",
    "\n",
    "# For the ROC-AUC Score, create a DataFrame with it as a value if needed\n",
    "roc_auc_df = pd.DataFrame({'ROC-AUC Score': [roc_auc]})\n",
    "\n",
    "# Display the DataFrames\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_df)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report_df)\n",
    "print(\"\\nROC-AUC Score:\")\n",
    "print(roc_auc_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation\n",
    "\n",
    "Confusion Matrix: The model performs well in identifying true positives (offers that were viewed). However, it struggles with false positives, predicting some offers as viewed when they were not.\n",
    "\n",
    "Classification Report:\n",
    "    Precision for class 1 (offers viewed) is 0.82, indicating that when the model predicts an offer was viewed, it is correct 82% of the time.\n",
    "    Recall for class 1 is 0.95, meaning the model successfully identifies 95% of the viewed offers.\n",
    "    Class 0 (offers not viewed) has lower precision and recall, indicating the model is less reliable at predicting non-viewed offers.\n",
    "\n",
    "ROC-AUC Score: The ROC-AUC score of 0.834 indicates good model performance, as a score closer to 1 is better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "The model is fairly accurate, particularly for predicting offers that were viewed. However, it has room for improvement in predicting offers that were not viewed (class 0). Considering the context and the baseline performance, 80.12% accuracy with a good ROC-AUC score suggests the model is performing well, but you might want to focus on improving the balance between precision and recall for the less frequent class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
