{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "df = pd.read_pickle(r'data\\04_fct\\fct_demographic_offers_and_transactions.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data, gender_column):\n",
    "    # Filter data for the specified gender\n",
    "    gender_data = data[data[gender_column] == 1]\n",
    "    # Drop 'gender_F' and 'gender_M' columns\n",
    "    gender_data = gender_data.drop(['gender_F', 'gender_M'], axis=1)\n",
    "    # Extract features and target variable\n",
    "    features = gender_data[['mobile', 'social', 'web']]\n",
    "    target = gender_data['offer_viewed']\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def train_evaluate_model(X_train, X_test, y_train, y_test):\n",
    "    # Initialize and train the random forest classifier with balanced class weights\n",
    "    rf_clf = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "    rf_clf.fit(X_train, y_train)\n",
    "    # Make predictions\n",
    "    y_pred = rf_clf.predict(X_test)\n",
    "    y_prob = rf_clf.predict_proba(X_test)[:, 1]\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred, zero_division=0)\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)\n",
    "    # Calculate permutation importance\n",
    "    perm_importance = permutation_importance(rf_clf, X_test, y_test, n_repeats=10, random_state=42)\n",
    "    perm_importance_df = pd.DataFrame({'Feature': ['mobile', 'social', 'web'],\n",
    "                                       'Importance': perm_importance.importances_mean,\n",
    "                                       'Importance STD': perm_importance.importances_std})\n",
    "    return {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Confusion Matrix\": conf_matrix,\n",
    "        \"Classification Report\": class_report,\n",
    "        \"ROC-AUC Score\": roc_auc,\n",
    "        \"Permutation Importance\": perm_importance_df\n",
    "    }\n",
    "\n",
    "# Process data for female and male customers\n",
    "X_train_female, X_test_female, y_train_female, y_test_female = process_data(df, 'gender_F')\n",
    "X_train_male, X_test_male, y_train_male, y_test_male = process_data(df, 'gender_M')\n",
    "\n",
    "# Train and evaluate models for female and male customers\n",
    "results_female = train_evaluate_model(X_train_female, X_test_female, y_train_female, y_test_female)\n",
    "results_male = train_evaluate_model(X_train_male, X_test_male, y_train_male, y_test_male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "      <th>Percent Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.758170</td>\n",
       "      <td>0.755670</td>\n",
       "      <td>0.330296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROC-AUC Score</td>\n",
       "      <td>0.841335</td>\n",
       "      <td>0.829774</td>\n",
       "      <td>1.383557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Confusion Matrix TN</td>\n",
       "      <td>573.000000</td>\n",
       "      <td>545.000000</td>\n",
       "      <td>5.008945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Confusion Matrix FP</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>-1.092896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Confusion Matrix FN</td>\n",
       "      <td>871.000000</td>\n",
       "      <td>953.000000</td>\n",
       "      <td>-8.991228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Confusion Matrix TP</td>\n",
       "      <td>2443.000000</td>\n",
       "      <td>2687.000000</td>\n",
       "      <td>-9.512671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>F1-Score (Macro)</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>2.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>F1-Score (Weighted)</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Importance of mobile</td>\n",
       "      <td>0.011689</td>\n",
       "      <td>0.008768</td>\n",
       "      <td>28.561824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Importance STD of mobile</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.001088</td>\n",
       "      <td>56.200257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Importance of social</td>\n",
       "      <td>0.168225</td>\n",
       "      <td>0.147346</td>\n",
       "      <td>13.232480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Importance STD of social</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>0.004807</td>\n",
       "      <td>-35.251220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Importance of web</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Importance STD of web</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Metric       Female         Male  Percent Difference\n",
       "0                   Accuracy     0.758170     0.755670            0.330296\n",
       "1              ROC-AUC Score     0.841335     0.829774            1.383557\n",
       "2        Confusion Matrix TN   573.000000   545.000000            5.008945\n",
       "3        Confusion Matrix FP    91.000000    92.000000           -1.092896\n",
       "4        Confusion Matrix FN   871.000000   953.000000           -8.991228\n",
       "5        Confusion Matrix TP  2443.000000  2687.000000           -9.512671\n",
       "6           F1-Score (Macro)     0.690000     0.670000            2.941176\n",
       "7        F1-Score (Weighted)     0.790000     0.790000            0.000000\n",
       "8       Importance of mobile     0.011689     0.008768           28.561824\n",
       "9   Importance STD of mobile     0.001938     0.001088           56.200257\n",
       "10      Importance of social     0.168225     0.147346           13.232480\n",
       "11  Importance STD of social     0.003367     0.004807          -35.251220\n",
       "12         Importance of web     0.000000     0.000000                 NaN\n",
       "13     Importance STD of web     0.000000     0.000000                 NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Parse model's evaluation results ###\n",
    "# Initialize the data dictionary\n",
    "data = {\n",
    "    \"Metric\": [],\n",
    "    \"Female\": [],\n",
    "    \"Male\": []\n",
    "}\n",
    "\n",
    "# Add accuracy and ROC-AUC Score\n",
    "data[\"Metric\"].append(\"Accuracy\")\n",
    "data[\"Female\"].append(results_female[\"Accuracy\"])\n",
    "data[\"Male\"].append(results_male[\"Accuracy\"])\n",
    "\n",
    "data[\"Metric\"].append(\"ROC-AUC Score\")\n",
    "data[\"Female\"].append(results_female[\"ROC-AUC Score\"])\n",
    "data[\"Male\"].append(results_male[\"ROC-AUC Score\"])\n",
    "\n",
    "# Add confusion matrix\n",
    "data[\"Metric\"].extend([\"Confusion Matrix TN\", \"Confusion Matrix FP\", \"Confusion Matrix FN\", \"Confusion Matrix TP\"])\n",
    "data[\"Female\"].extend(results_female[\"Confusion Matrix\"].flatten().tolist())\n",
    "data[\"Male\"].extend(results_male[\"Confusion Matrix\"].flatten().tolist())\n",
    "\n",
    "# Function to extract F1-scores for macro and weighted averages\n",
    "def extract_f1_scores(report):\n",
    "    lines = report.split('\\n')\n",
    "    f1_scores = {}\n",
    "    for line in lines:\n",
    "        if \"macro avg\" in line:\n",
    "            f1_scores['F1-Score (Macro)'] = line.split()[-2]  # Assuming F1-score is the second last element\n",
    "        elif \"weighted avg\" in line:\n",
    "            f1_scores['F1-Score (Weighted)'] = line.split()[-2]  # Assuming F1-score is the second last element\n",
    "    return f1_scores\n",
    "\n",
    "# Extract F1-scores for macro and weighted averages\n",
    "f1_scores_female = extract_f1_scores(results_female['Classification Report'])\n",
    "f1_scores_male = extract_f1_scores(results_male['Classification Report'])\n",
    "\n",
    "# Assuming classification_metrics includes the metrics you're interested in\n",
    "classification_metrics = ['F1-Score (Macro)', 'F1-Score (Weighted)']\n",
    "\n",
    "# Loop through each metric and append the results to the data dictionary\n",
    "for metric_name in classification_metrics:\n",
    "    data[\"Metric\"].append(metric_name)\n",
    "    data[\"Female\"].append(f1_scores_female[metric_name])\n",
    "    data[\"Male\"].append(f1_scores_male[metric_name])\n",
    "\n",
    "# Add permutation importance\n",
    "for index, feature in enumerate(results_female['Permutation Importance']['Feature']):\n",
    "    data[\"Metric\"].append(f'Importance of {feature}')\n",
    "    data[\"Female\"].append(results_female['Permutation Importance']['Importance'][index])\n",
    "    data[\"Male\"].append(results_male['Permutation Importance']['Importance'][index])\n",
    "    \n",
    "    data[\"Metric\"].append(f'Importance STD of {feature}')\n",
    "    data[\"Female\"].append(results_female['Permutation Importance']['Importance STD'][index])\n",
    "    data[\"Male\"].append(results_male['Permutation Importance']['Importance STD'][index])\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate the percent difference\n",
    "# Convert 'Female' and 'Male' columns to numeric (float) to ensure calculations can be performed\n",
    "df['Female'] = pd.to_numeric(df['Female'], errors='coerce')\n",
    "df['Male'] = pd.to_numeric(df['Male'], errors='coerce')\n",
    "\n",
    "# Calculate percent difference\n",
    "condition_both_non_zero = (df['Female'] != 0) & (df['Male'] != 0)\n",
    "condition_one_zero = (df['Female'] == 0) | (df['Male'] == 0)\n",
    "condition_both_zero = (df['Female'] == 0) & (df['Male'] == 0)\n",
    "\n",
    "# Calculate percent difference\n",
    "df['Percent Difference'] = np.nan\n",
    "df.loc[condition_both_non_zero, 'Percent Difference'] = ((df['Female'] - df['Male']) / ((df['Female'] + df['Male']) / 2)) * 100\n",
    "df.loc[condition_one_zero & ~condition_both_zero, 'Percent Difference'] = np.nan\n",
    "\n",
    "df.to_csv(r'data/04_fct/fct_offer_channel_importance_evaluation_results.csv', index=False)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
